{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Using cached https://files.pythonhosted.org/packages/2e/bd/ad3a963b630fa3ee72d1a672fd207263fa0a18113688273afe8298293535/xgboost-0.82.tar.gz\n",
      "Requirement already satisfied: numpy in /Users/weiyudu/anaconda3/lib/python3.7/site-packages (from xgboost) (1.15.4)\n",
      "Requirement already satisfied: scipy in /Users/weiyudu/anaconda3/lib/python3.7/site-packages (from xgboost) (1.1.0)\n",
      "Building wheels for collected packages: xgboost\n",
      "  Building wheel for xgboost (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/weiyudu/Library/Caches/pip/wheels/5d/ea/e9/4aef52d7294badf6bc26728a73d3e001c38e07f7dc3722c5eb\n",
      "Successfully built xgboost\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-0.82\n"
     ]
    }
   ],
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [13, 14, 15, 16]\n",
    "taxi_df = {}\n",
    "for i in [13, 14, 15, 16]:\n",
    "    taxi_df[i] = pd.read_csv(\"download/20\" + str(i) \\\n",
    "                             + \"lag.csv\",\\\n",
    "                                    sep = \",\")\n",
    "y_df = {}\n",
    "X_raw_df = {}\n",
    "for i in years:\n",
    "    y_df[i] =  pd.DataFrame(taxi_df[i]['Count'])\n",
    "    X_raw_df[i] = taxi_df[i].drop(columns = ['Pickup Community Area', \\\n",
    "                                             'Count', 'Trip Start Timestamp'])\n",
    "    \n",
    "weekdays = ['0','1','2','3','4','5','6']\n",
    "enc = OneHotEncoder(categories=[weekdays])\n",
    "encoded_df = {}\n",
    "for i in years:\n",
    "    enc.fit(X_raw_df[i].weekday.values.reshape(-1, 1))\n",
    "    encoded_df[i] = pd.DataFrame(enc.transform(X_raw_df[i].weekday.values.reshape(-1, 1))\\\n",
    "                                 .toarray().astype(int))\\\n",
    "                                .rename(columns = {0: 'Monday', 1:'Tuesday', 2:'Wedneseday',\\\n",
    "                                3:'Thursday', 4:'Friday', 5:'Saturday',\\\n",
    "                                6:'Sunday'})\n",
    "\n",
    "X_encode_df = {}\n",
    "for i in years:\n",
    "    X_encode_df[i] = pd.concat([X_raw_df[i].drop(columns=['weekday']), encoded_df[i]], axis=1)\n",
    "\n",
    "X_mat = {}\n",
    "y_mat = {}\n",
    "for i in years:\n",
    "    X_mat[i] = X_encode_df[i].values\n",
    "    y_mat[i] = y_df[i].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPRegressor(hidden_layer_sizes=(5, 5, 5), activation='relu', solver='adam', \n",
    "                   alpha=0.0001, batch_size='auto', learning_rate='constant', \n",
    "                   learning_rate_init=0.001, power_t=0.5, max_iter=1000, shuffle=True, \n",
    "                   random_state=None, tol=0.0001, verbose=True, warm_start=False, momentum=0.9, \n",
    "                   nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, \n",
    "                   beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weiyudu/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1017.55345040\n",
      "Iteration 2, loss = 314.58324586\n",
      "Iteration 3, loss = 302.93658492\n",
      "Iteration 4, loss = 297.55095098\n",
      "Iteration 5, loss = 290.47016009\n",
      "Iteration 6, loss = 286.90581301\n",
      "Iteration 7, loss = 284.11860586\n",
      "Iteration 8, loss = 280.87782100\n",
      "Iteration 9, loss = 279.29500453\n",
      "Iteration 10, loss = 276.42883819\n",
      "Iteration 11, loss = 276.46476969\n",
      "Iteration 12, loss = 276.14883500\n",
      "Iteration 13, loss = 272.49355680\n",
      "Iteration 14, loss = 271.26967174\n",
      "Iteration 15, loss = 271.21990967\n",
      "Iteration 16, loss = 271.90178220\n",
      "Iteration 17, loss = 270.45785022\n",
      "Iteration 18, loss = 269.12961389\n",
      "Iteration 19, loss = 267.75764029\n",
      "Iteration 20, loss = 268.74915604\n",
      "Iteration 21, loss = 269.42471413\n",
      "Iteration 22, loss = 264.56562432\n",
      "Iteration 23, loss = 266.57902610\n",
      "Iteration 24, loss = 266.27688117\n",
      "Iteration 25, loss = 263.87129749\n",
      "Iteration 26, loss = 264.98268100\n",
      "Iteration 27, loss = 263.38356671\n",
      "Iteration 28, loss = 264.01694883\n",
      "Iteration 29, loss = 264.88943763\n",
      "Iteration 30, loss = 262.53445369\n",
      "Iteration 31, loss = 262.02010393\n",
      "Iteration 32, loss = 262.43849174\n",
      "Iteration 33, loss = 262.38219203\n",
      "Iteration 34, loss = 262.31879327\n",
      "Iteration 35, loss = 261.65990205\n",
      "Iteration 36, loss = 261.01561288\n",
      "Iteration 37, loss = 259.43175986\n",
      "Iteration 38, loss = 260.25508802\n",
      "Iteration 39, loss = 258.18853271\n",
      "Iteration 40, loss = 260.68403381\n",
      "Iteration 41, loss = 257.00170444\n",
      "Iteration 42, loss = 259.28349266\n",
      "Iteration 43, loss = 259.36456513\n",
      "Iteration 44, loss = 257.13076773\n",
      "Iteration 45, loss = 256.35144093\n",
      "Iteration 46, loss = 257.30178817\n",
      "Iteration 47, loss = 255.17457874\n",
      "Iteration 48, loss = 255.34933546\n",
      "Iteration 49, loss = 255.23839997\n",
      "Iteration 50, loss = 255.49129053\n",
      "Iteration 51, loss = 254.11495246\n",
      "Iteration 52, loss = 253.57135012\n",
      "Iteration 53, loss = 252.63877981\n",
      "Iteration 54, loss = 253.04946841\n",
      "Iteration 55, loss = 252.14848338\n",
      "Iteration 56, loss = 250.95409246\n",
      "Iteration 57, loss = 249.33154141\n",
      "Iteration 58, loss = 251.58899299\n",
      "Iteration 59, loss = 250.59763901\n",
      "Iteration 60, loss = 249.45427903\n",
      "Iteration 61, loss = 249.37613395\n",
      "Iteration 62, loss = 249.38198049\n",
      "Iteration 63, loss = 247.68251224\n",
      "Iteration 64, loss = 247.28339295\n",
      "Iteration 65, loss = 247.02680082\n",
      "Iteration 66, loss = 244.98275592\n",
      "Iteration 67, loss = 246.18032304\n",
      "Iteration 68, loss = 245.34259071\n",
      "Iteration 69, loss = 244.10966461\n",
      "Iteration 70, loss = 244.69979761\n",
      "Iteration 71, loss = 242.84013424\n",
      "Iteration 72, loss = 242.63514784\n",
      "Iteration 73, loss = 243.02007333\n",
      "Iteration 74, loss = 241.89151669\n",
      "Iteration 75, loss = 241.38279591\n",
      "Iteration 76, loss = 241.03488227\n",
      "Iteration 77, loss = 241.34877471\n",
      "Iteration 78, loss = 240.39176261\n",
      "Iteration 79, loss = 239.55044574\n",
      "Iteration 80, loss = 238.85596371\n",
      "Iteration 81, loss = 237.63236362\n",
      "Iteration 82, loss = 237.96739630\n",
      "Iteration 83, loss = 237.31649786\n",
      "Iteration 84, loss = 236.82379749\n",
      "Iteration 85, loss = 235.85512975\n",
      "Iteration 86, loss = 235.88878459\n",
      "Iteration 87, loss = 233.04485805\n",
      "Iteration 88, loss = 232.70362069\n",
      "Iteration 89, loss = 232.66683287\n",
      "Iteration 90, loss = 232.42322205\n",
      "Iteration 91, loss = 230.52562991\n",
      "Iteration 92, loss = 229.95084559\n",
      "Iteration 93, loss = 230.08025999\n",
      "Iteration 94, loss = 230.14942169\n",
      "Iteration 95, loss = 228.24540282\n",
      "Iteration 96, loss = 228.59138043\n",
      "Iteration 97, loss = 228.15868930\n",
      "Iteration 98, loss = 227.41080410\n",
      "Iteration 99, loss = 226.37911169\n",
      "Iteration 100, loss = 225.26543760\n",
      "Iteration 101, loss = 226.73193982\n",
      "Iteration 102, loss = 225.10310909\n",
      "Iteration 103, loss = 224.19056865\n",
      "Iteration 104, loss = 222.05871630\n",
      "Iteration 105, loss = 223.38021042\n",
      "Iteration 106, loss = 221.18371660\n",
      "Iteration 107, loss = 222.38518804\n",
      "Iteration 108, loss = 221.45397062\n",
      "Iteration 109, loss = 221.08018676\n",
      "Iteration 110, loss = 218.22150381\n",
      "Iteration 111, loss = 219.62297581\n",
      "Iteration 112, loss = 219.02510228\n",
      "Iteration 113, loss = 219.39822259\n",
      "Iteration 114, loss = 219.05172950\n",
      "Iteration 115, loss = 217.93133541\n",
      "Iteration 116, loss = 218.25493483\n",
      "Iteration 117, loss = 218.55386421\n",
      "Iteration 118, loss = 218.98825080\n",
      "Iteration 119, loss = 217.01888379\n",
      "Iteration 120, loss = 215.79959553\n",
      "Iteration 121, loss = 216.95617056\n",
      "Iteration 122, loss = 216.98320085\n",
      "Iteration 123, loss = 218.83514561\n",
      "Iteration 124, loss = 214.79031040\n",
      "Iteration 125, loss = 215.50619000\n",
      "Iteration 126, loss = 216.63875267\n",
      "Iteration 127, loss = 216.88564102\n",
      "Iteration 128, loss = 215.24117322\n",
      "Iteration 129, loss = 213.79376147\n",
      "Iteration 130, loss = 214.89672401\n",
      "Iteration 131, loss = 214.24633368\n",
      "Iteration 132, loss = 214.34247538\n",
      "Iteration 133, loss = 213.18480880\n",
      "Iteration 134, loss = 214.53102878\n",
      "Iteration 135, loss = 212.83877595\n",
      "Iteration 136, loss = 212.85023114\n",
      "Iteration 137, loss = 213.55842557\n",
      "Iteration 138, loss = 211.10906295\n",
      "Iteration 139, loss = 212.27432774\n",
      "Iteration 140, loss = 211.38409861\n",
      "Iteration 141, loss = 212.02344446\n",
      "Iteration 142, loss = 212.45378248\n",
      "Iteration 143, loss = 209.40782821\n",
      "Iteration 144, loss = 213.12873544\n",
      "Iteration 145, loss = 211.01097859\n",
      "Iteration 146, loss = 213.86744681\n",
      "Iteration 147, loss = 211.18528726\n",
      "Iteration 148, loss = 208.92518681\n",
      "Iteration 149, loss = 209.53612693\n",
      "Iteration 150, loss = 213.55469981\n",
      "Iteration 151, loss = 210.59760876\n",
      "Iteration 152, loss = 210.67434223\n",
      "Iteration 153, loss = 209.26478545\n",
      "Iteration 154, loss = 211.17369737\n",
      "Iteration 155, loss = 212.23388736\n",
      "Iteration 156, loss = 208.62252403\n",
      "Iteration 157, loss = 210.87627660\n",
      "Iteration 158, loss = 207.63208032\n",
      "Iteration 159, loss = 209.97990217\n",
      "Iteration 160, loss = 210.46724311\n",
      "Iteration 161, loss = 209.66012106\n",
      "Iteration 162, loss = 210.27307452\n",
      "Iteration 163, loss = 210.41097592\n",
      "Iteration 164, loss = 207.81746767\n",
      "Iteration 165, loss = 212.17322728\n",
      "Iteration 166, loss = 208.39870079\n",
      "Iteration 167, loss = 207.91327576\n",
      "Iteration 168, loss = 206.22864020\n",
      "Iteration 169, loss = 209.35500024\n",
      "Iteration 170, loss = 206.19915762\n",
      "Iteration 171, loss = 205.74579824\n",
      "Iteration 172, loss = 206.56562469\n",
      "Iteration 173, loss = 208.57116301\n",
      "Iteration 174, loss = 206.40066620\n",
      "Iteration 175, loss = 205.27016523\n",
      "Iteration 176, loss = 206.59448036\n",
      "Iteration 177, loss = 205.56138234\n",
      "Iteration 178, loss = 207.33095652\n",
      "Iteration 179, loss = 205.84164631\n",
      "Iteration 180, loss = 203.13889905\n",
      "Iteration 181, loss = 206.19651987\n",
      "Iteration 182, loss = 207.51232878\n",
      "Iteration 183, loss = 205.29267489\n",
      "Iteration 184, loss = 208.79606608\n",
      "Iteration 185, loss = 206.48101979\n",
      "Iteration 186, loss = 206.29461134\n",
      "Iteration 187, loss = 206.11918933\n",
      "Iteration 188, loss = 204.72752799\n",
      "Iteration 189, loss = 208.04200681\n",
      "Iteration 190, loss = 203.48138137\n",
      "Iteration 191, loss = 204.69369232\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "261.7320957900167"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_mlp = mlp.fit(X_mat[15], y_mat[15])\n",
    "predictions = my_mlp.predict(X_mat[16])\n",
    "mean_squared_error(y_true = y_mat[16], y_pred = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weiyudu/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/weiyudu/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348.9126427019412\n"
     ]
    }
   ],
   "source": [
    "mlp_3_10_13 = MLPRegressor(hidden_layer_sizes=(10, 10, 10), activation='relu', solver='adam', \n",
    "                   alpha=0.0001, batch_size='auto', learning_rate='constant', \n",
    "                   learning_rate_init=0.001, power_t=0.5, max_iter=1000, shuffle=True, \n",
    "                   random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "                   nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, \n",
    "                   beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10)\n",
    "mlp_3_10_13.fit(X_mat[13], y_mat[13])\n",
    "predictions = mlp_3_10_13.predict(X_mat[14])\n",
    "cv1 = mean_squared_error(y_true = y_mat[14], y_pred = predictions)\n",
    "\n",
    "mlp_3_10_14 = MLPRegressor(hidden_layer_sizes=(10, 10, 10), activation='relu', solver='adam', \n",
    "                   alpha=0.0001, batch_size='auto', learning_rate='constant', \n",
    "                   learning_rate_init=0.001, power_t=0.5, max_iter=1000, shuffle=True, \n",
    "                   random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "                   nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, \n",
    "                   beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10)\n",
    "mlp_3_10_14.fit(X_mat[14], y_mat[14])\n",
    "predictions = mlp_3_10_14.predict(X_mat[15])\n",
    "cv2 = mean_squared_error(y_true = y_mat[15], y_pred = predictions)\n",
    "print((cv1+cv2)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPRegressor(hidden_layer_sizes=(10,10,10,10,10,10,10,10,10,10), activation='relu', solver='adam', \n",
    "                   alpha=0.0001, batch_size='auto', learning_rate='constant', \n",
    "                   learning_rate_init=0.001, power_t=0.5, max_iter=1000, shuffle=True, \n",
    "                   random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "                   nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, \n",
    "                   beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weiyudu/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "403.96551146446205"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_mlp = mlp.fit(X_mat[13], y_mat[13])\n",
    "predictions = my_mlp.predict(X_mat[14])\n",
    "mean_squared_error(y_true = y_mat[14], y_pred = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weiyudu/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "229.50160415333298"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_mlp_2 = mlp.fit(X_mat[15], y_mat[15])\n",
    "predictions = my_mlp_2.predict(X_mat[16])\n",
    "mean_squared_error(y_true = y_mat[16], y_pred = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278.0389922102762"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = my_mlp_2.predict(X_mat[15])\n",
    "mean_squared_error(y_true = y_mat[15], y_pred = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weiyudu/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "430.1633335787159"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_10_10_14 = MLPRegressor(hidden_layer_sizes=(10,10,10,10,10,10,10,10,10,10), activation='relu', solver='adam', \n",
    "                   alpha=0.0001, batch_size='auto', learning_rate='constant', \n",
    "                   learning_rate_init=0.001, power_t=0.5, max_iter=1000, shuffle=True, \n",
    "                   random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "                   nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, \n",
    "                   beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10)\n",
    "mlp_10_10_14.fit(X_mat[14], y_mat[14])\n",
    "predictions = mlp_10_10_14.predict(X_mat[15])\n",
    "mean_squared_error(y_true = y_mat[15], y_pred = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "417.064422521589"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(403.96551146446205+430.1633335787159)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_tmp = MLPRegressor(hidden_layer_sizes=(50,50,50,50,50), activation='relu', solver='adam', \n",
    "                   alpha=0.0001, batch_size='auto', learning_rate='constant', \n",
    "                   learning_rate_init=0.001, power_t=0.5, max_iter=1000, shuffle=True, \n",
    "                   random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "                   nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, \n",
    "                   beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weiyudu/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "188.9100065565994"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_tmp.fit(X_mat[15],y_mat[15])\n",
    "predictions = mlp_tmp.predict(X_mat[16])\n",
    "mean_squared_error(y_true = y_mat[16], y_pred = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212.282356177718"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = mlp_tmp.predict(X_mat[15])\n",
    "mean_squared_error(y_true = y_mat[15], y_pred = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weiyudu/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/weiyudu/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331.72767764966346\n"
     ]
    }
   ],
   "source": [
    "mlp_5_50_13 = MLPRegressor(hidden_layer_sizes=(50,50,50,50,50), activation='relu', solver='adam', \n",
    "                   alpha=0.0001, batch_size='auto', learning_rate='constant', \n",
    "                   learning_rate_init=0.001, power_t=0.5, max_iter=1000, shuffle=True, \n",
    "                   random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "                   nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, \n",
    "                   beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10)\n",
    "mlp_5_50_13.fit(X_mat[13],y_mat[13])\n",
    "predictions = mlp_5_50_13.predict(X_mat[14])\n",
    "cv1 = mean_squared_error(y_true = y_mat[14], y_pred = predictions)\n",
    "\n",
    "mlp_5_50_14 = MLPRegressor(hidden_layer_sizes=(50,50,50,50,50), activation='relu', solver='adam', \n",
    "                   alpha=0.0001, batch_size='auto', learning_rate='constant', \n",
    "                   learning_rate_init=0.001, power_t=0.5, max_iter=1000, shuffle=True, \n",
    "                   random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "                   nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, \n",
    "                   beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10)\n",
    "mlp_5_50_14.fit(X_mat[14],y_mat[14])\n",
    "predictions = mlp_5_50_14.predict(X_mat[15])\n",
    "cv2 = mean_squared_error(y_true = y_mat[15], y_pred = predictions)\n",
    "print((cv1+cv2)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weiyudu/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "178.65290904124373"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_100_5 = MLPRegressor(hidden_layer_sizes=(100,100,100,100,100), activation='relu', solver='adam', \n",
    "                   alpha=0.0001, batch_size='auto', learning_rate='constant', \n",
    "                   learning_rate_init=0.001, power_t=0.5, max_iter=1000, shuffle=True, \n",
    "                   random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "                   nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, \n",
    "                   beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10)\n",
    "mlp_100_5.fit(X_mat[15],y_mat[15])\n",
    "predictions = mlp_100_5.predict(X_mat[16])\n",
    "mean_squared_error(y_true = y_mat[16], y_pred = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232.13215330019108"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = mlp_100_5.predict(X_mat[15])\n",
    "mean_squared_error(y_true = y_mat[15], y_pred = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weiyudu/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "328.63645892053694"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_5_100_13 = MLPRegressor(hidden_layer_sizes=(100,100,100,100,100), activation='relu', solver='adam', \n",
    "                   alpha=0.0001, batch_size='auto', learning_rate='constant', \n",
    "                   learning_rate_init=0.001, power_t=0.5, max_iter=1000, shuffle=True, \n",
    "                   random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "                   nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, \n",
    "                   beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10)\n",
    "mlp_5_100_13.fit(X_mat[13],y_mat[13])\n",
    "predictions = mlp_5_100_13.predict(X_mat[14])\n",
    "mean_squared_error(y_true = y_mat[14], y_pred = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weiyudu/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "293.4599875194084"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_5_100_14 = MLPRegressor(hidden_layer_sizes=(100,100,100,100,100), activation='relu', solver='adam', \n",
    "                   alpha=0.0001, batch_size='auto', learning_rate='constant', \n",
    "                   learning_rate_init=0.001, power_t=0.5, max_iter=1000, shuffle=True, \n",
    "                   random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "                   nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, \n",
    "                   beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10)\n",
    "mlp_5_100_14.fit(X_mat[14],y_mat[14])\n",
    "predictions = mlp_5_100_13.predict(X_mat[15])\n",
    "mean_squared_error(y_true = y_mat[15], y_pred = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "291.8239704655969"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = mlp_5_100_14.predict(X_mat[15])\n",
    "mean_squared_error(y_true = y_mat[15], y_pred = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "310.23021469306696"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(291.8239704655969+328.63645892053694)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weiyudu/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/weiyudu/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394.23187957107245\n"
     ]
    }
   ],
   "source": [
    "mlp_5_10_13 = MLPRegressor(hidden_layer_sizes=(10,10,10,10,10), activation='relu', solver='adam', \n",
    "                   alpha=0.0001, batch_size='auto', learning_rate='constant', \n",
    "                   learning_rate_init=0.001, power_t=0.5, max_iter=1000, shuffle=True, \n",
    "                   random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "                   nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, \n",
    "                   beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10)\n",
    "mlp_5_10_13.fit(X_mat[13],y_mat[13])\n",
    "predictions = mlp_5_10_13.predict(X_mat[14])\n",
    "cv1 = mean_squared_error(y_true = y_mat[14], y_pred = predictions)\n",
    "\n",
    "mlp_5_10_14 = MLPRegressor(hidden_layer_sizes=(10,10,10,10,10), activation='relu', solver='adam', \n",
    "                   alpha=0.0001, batch_size='auto', learning_rate='constant', \n",
    "                   learning_rate_init=0.001, power_t=0.5, max_iter=1000, shuffle=True, \n",
    "                   random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "                   nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, \n",
    "                   beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10)\n",
    "mlp_5_10_14.fit(X_mat[14],y_mat[14])\n",
    "predictions = mlp_5_10_14.predict(X_mat[15])\n",
    "cv2 = mean_squared_error(y_true = y_mat[15], y_pred = predictions)\n",
    "print((cv1+cv2)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weiyudu/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/weiyudu/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293.5787835554945\n"
     ]
    }
   ],
   "source": [
    "mlp_3_50_13 = MLPRegressor(hidden_layer_sizes=(50,50,50), activation='relu', solver='adam', \n",
    "                   alpha=0.0001, batch_size='auto', learning_rate='constant', \n",
    "                   learning_rate_init=0.001, power_t=0.5, max_iter=1000, shuffle=True, \n",
    "                   random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "                   nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, \n",
    "                   beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10)\n",
    "mlp_3_50_13.fit(X_mat[13],y_mat[13])\n",
    "predictions = mlp_3_50_13.predict(X_mat[14])\n",
    "cv1 = mean_squared_error(y_true = y_mat[14], y_pred = predictions)\n",
    "\n",
    "mlp_3_50_14 = MLPRegressor(hidden_layer_sizes=(50,50,50), activation='relu', solver='adam', \n",
    "                   alpha=0.0001, batch_size='auto', learning_rate='constant', \n",
    "                   learning_rate_init=0.001, power_t=0.5, max_iter=1000, shuffle=True, \n",
    "                   random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "                   nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, \n",
    "                   beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10)\n",
    "mlp_3_50_14.fit(X_mat[14],y_mat[14])\n",
    "predictions = mlp_3_50_14.predict(X_mat[15])\n",
    "cv2 = mean_squared_error(y_true = y_mat[15], y_pred = predictions)\n",
    "print((cv1+cv2)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weiyudu/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200.84005394701964"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_3_50_15 = MLPRegressor(hidden_layer_sizes=(50,50,50), activation='relu', solver='adam', \n",
    "                   alpha=0.0001, batch_size='auto', learning_rate='constant', \n",
    "                   learning_rate_init=0.001, power_t=0.5, max_iter=1000, shuffle=True, \n",
    "                   random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "                   nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, \n",
    "                   beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10)\n",
    "mlp_3_50_15.fit(X_mat[15],y_mat[15])\n",
    "predictions = mlp_3_50_15.predict(X_mat[16])\n",
    "mean_squared_error(y_true = y_mat[16], y_pred = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212.3496371713842"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = mlp_3_50_15.predict(X_mat[15])\n",
    "mean_squared_error(y_true = y_mat[15], y_pred = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weiyudu/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "179.61364491630317"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_50_10 = MLPRegressor(hidden_layer_sizes=(50,50,50,50,50,50,50,50,50,50), activation='relu', solver='adam', \n",
    "                   alpha=0.0001, batch_size='auto', learning_rate='constant', \n",
    "                   learning_rate_init=0.001, power_t=0.5, max_iter=1000, shuffle=True, \n",
    "                   random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "                   nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, \n",
    "                   beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10)\n",
    "mlp_50_10.fit(X_mat[15],y_mat[15])\n",
    "predictions = mlp_50_10.predict(X_mat[16])\n",
    "mean_squared_error(y_true = y_mat[16], y_pred = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226.19209540376093"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = mlp_50_10.predict(X_mat[15])\n",
    "mean_squared_error(y_true = y_mat[15], y_pred = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weiyudu/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/weiyudu/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306.292019147817\n"
     ]
    }
   ],
   "source": [
    "mlp_50_10_13 = MLPRegressor(hidden_layer_sizes=(50,50,50,50,50,50,50,50,50,50), activation='relu', solver='adam', \n",
    "                   alpha=0.0001, batch_size='auto', learning_rate='constant', \n",
    "                   learning_rate_init=0.001, power_t=0.5, max_iter=1000, shuffle=True, \n",
    "                   random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "                   nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, \n",
    "                   beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10)\n",
    "mlp_50_10_13.fit(X_mat[13],y_mat[13])\n",
    "predictions = mlp_50_10_13.predict(X_mat[14])\n",
    "cv1 = mean_squared_error(y_true = y_mat[14], y_pred = predictions)\n",
    "\n",
    "mlp_50_10_14 = MLPRegressor(hidden_layer_sizes=(50,50,50,50,50,50,50,50,50,50), activation='relu', solver='adam', \n",
    "                   alpha=0.0001, batch_size='auto', learning_rate='constant', \n",
    "                   learning_rate_init=0.001, power_t=0.5, max_iter=1000, shuffle=True, \n",
    "                   random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "                   nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, \n",
    "                   beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10)\n",
    "mlp_50_10_14.fit(X_mat[14],y_mat[14])\n",
    "predictions = mlp_50_10_14.predict(X_mat[15])\n",
    "cv2 = mean_squared_error(y_true = y_mat[15], y_pred = predictions)\n",
    "print((cv1+cv2)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weiyudu/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306.27373385130153\n"
     ]
    }
   ],
   "source": [
    "predictions = mlp_50_10_13.predict(X_mat[14])\n",
    "cv1 = mean_squared_error(y_true = y_mat[14], y_pred = predictions)\n",
    "mlp_50_10_14.fit(X_mat[14],y_mat[14])\n",
    "predictions = mlp_50_10_14.predict(X_mat[15])\n",
    "cv2 = mean_squared_error(y_true = y_mat[15], y_pred = predictions)\n",
    "print((cv1+cv2)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weiyudu/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "179.61364491630317"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_100_10 = MLPRegressor(hidden_layer_sizes=(100,100,100,100,100,100,100,100,100,100), activation='relu', solver='adam', \n",
    "                   alpha=0.0001, batch_size='auto', learning_rate='constant', \n",
    "                   learning_rate_init=0.001, power_t=0.5, max_iter=1000, shuffle=True, \n",
    "                   random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "                   nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, \n",
    "                   beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10)\n",
    "mlp_100_10.fit(X_mat[15],y_mat[15])\n",
    "predictions = mlp_50_10.predict(X_mat[16])\n",
    "mean_squared_error(y_true = y_mat[16], y_pred = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211.71696677329822"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = mlp_100_10.predict(X_mat[16])\n",
    "mean_squared_error(y_true = y_mat[16], y_pred = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197.9314175015789"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = mlp_100_10.predict(X_mat[15])\n",
    "mean_squared_error(y_true = y_mat[15], y_pred = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weiyudu/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/weiyudu/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327.05765375515534\n"
     ]
    }
   ],
   "source": [
    "mlp_100_10_13 = MLPRegressor(hidden_layer_sizes=(100,100,100,100,100,100,100,100,100,100), activation='relu', solver='adam', \n",
    "                   alpha=0.0001, batch_size='auto', learning_rate='constant', \n",
    "                   learning_rate_init=0.001, power_t=0.5, max_iter=1000, shuffle=True, \n",
    "                   random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "                   nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, \n",
    "                   beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10)\n",
    "mlp_100_10_13.fit(X_mat[13],y_mat[13])\n",
    "predictions = mlp_50_10_13.predict(X_mat[14])\n",
    "cv1 = mean_squared_error(y_true = y_mat[14], y_pred = predictions)\n",
    "\n",
    "mlp_100_10_14 = MLPRegressor(hidden_layer_sizes=(100,100,100,100,100,100,100,100,100,100), activation='relu', solver='adam', \n",
    "                   alpha=0.0001, batch_size='auto', learning_rate='constant', \n",
    "                   learning_rate_init=0.001, power_t=0.5, max_iter=1000, shuffle=True, \n",
    "                   random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "                   nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, \n",
    "                   beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10)\n",
    "mlp_100_10_14.fit(X_mat[14],y_mat[14])\n",
    "predictions = mlp_50_10_14.predict(X_mat[15])\n",
    "cv2 = mean_squared_error(y_true = y_mat[15], y_pred = predictions)\n",
    "print((cv1+cv2)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301.51631153715596\n"
     ]
    }
   ],
   "source": [
    "predictions = mlp_100_10_13.predict(X_mat[14])\n",
    "cv1 = mean_squared_error(y_true = y_mat[14], y_pred = predictions)\n",
    "predictions = mlp_100_10_14.predict(X_mat[15])\n",
    "cv2 = mean_squared_error(y_true = y_mat[15], y_pred = predictions)\n",
    "print((cv1+cv2)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_3_50_13 = MLPRegressor(hidden_layer_sizes=(50,50,50), activation='relu', solver='adam', \n",
    "                   alpha=0.0001, batch_size='auto', learning_rate='constant', \n",
    "                   learning_rate_init=0.001, power_t=0.5, max_iter=1000, shuffle=True, \n",
    "                   random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "                   nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, \n",
    "                   beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10)\n",
    "mlp_3_50_13.fit(X_mat[13],y_mat[13])\n",
    "predictions = mlp_3_50_13.predict(X_mat[14])\n",
    "cv1 = mean_squared_error(y_true = y_mat[14], y_pred = predictions)\n",
    "\n",
    "mlp_100_10_14 = MLPRegressor(hidden_layer_sizes=(100,100,100,100,100,100,100,100,100,100), activation='relu', solver='adam', \n",
    "                   alpha=0.0001, batch_size='auto', learning_rate='constant', \n",
    "                   learning_rate_init=0.001, power_t=0.5, max_iter=1000, shuffle=True, \n",
    "                   random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "                   nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, \n",
    "                   beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10)\n",
    "mlp_100_10_14.fit(X_mat[14],y_mat[14])\n",
    "predictions = mlp_50_10_14.predict(X_mat[15])\n",
    "cv2 = mean_squared_error(y_true = y_mat[15], y_pred = predictions)\n",
    "print((cv1+cv2)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weiyudu/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176.95342782633017\n",
      "192.06407912471036\n"
     ]
    }
   ],
   "source": [
    "mlp_3_100 = MLPRegressor(hidden_layer_sizes=(100,100,100), activation='relu', solver='adam', \n",
    "                   alpha=0.0001, batch_size='auto', learning_rate='constant', \n",
    "                   learning_rate_init=0.001, power_t=0.5, max_iter=1000, shuffle=True, \n",
    "                   random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "                   nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, \n",
    "                   beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10)\n",
    "mlp_3_100.fit(X_mat[15],y_mat[15])\n",
    "predictions = mlp_3_100.predict(X_mat[16])\n",
    "print(mean_squared_error(y_true = y_mat[16], y_pred = predictions))\n",
    "predictions = mlp_3_100.predict(X_mat[15])\n",
    "print(mean_squared_error(y_true = y_mat[15], y_pred = predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weiyudu/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347.58604452158005\n",
      "213.3027591524016\n"
     ]
    }
   ],
   "source": [
    "mlp_3_100_13 = MLPRegressor(hidden_layer_sizes=(100,100,100), activation='relu', solver='adam', \n",
    "                   alpha=0.0001, batch_size='auto', learning_rate='constant', \n",
    "                   learning_rate_init=0.001, power_t=0.5, max_iter=1000, shuffle=True, \n",
    "                   random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "                   nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, \n",
    "                   beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10)\n",
    "mlp_3_100_13.fit(X_mat[13],y_mat[13])\n",
    "predictions = mlp_3_100_13.predict(X_mat[14])\n",
    "print(mean_squared_error(y_true = y_mat[14], y_pred = predictions))\n",
    "predictions = mlp_3_100_13.predict(X_mat[13])\n",
    "print(mean_squared_error(y_true = y_mat[13], y_pred = predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weiyudu/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244.83755708916087\n"
     ]
    }
   ],
   "source": [
    "mlp_3_100_14 = MLPRegressor(hidden_layer_sizes=(100,100,100), activation='relu', solver='adam', \n",
    "                   alpha=0.0001, batch_size='auto', learning_rate='constant', \n",
    "                   learning_rate_init=0.001, power_t=0.5, max_iter=1000, shuffle=True, \n",
    "                   random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "                   nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, \n",
    "                   beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10)\n",
    "mlp_3_100_14.fit(X_mat[14],y_mat[14])\n",
    "predictions = mlp_3_100_14.predict(X_mat[15])\n",
    "print(mean_squared_error(y_true = y_mat[15], y_pred = predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = my_mlp.predict(X_mat[15])\n",
    "mean_squared_error(y_true = y_mat[16], y_pred = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157.2051801984971"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = my_xgb.predict(X_mat[15])\n",
    "mean_squared_error(y_true = y_mat[15], y_pred = predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
